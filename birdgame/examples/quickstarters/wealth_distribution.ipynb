{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91566d3",
   "metadata": {},
   "source": [
    "# Run the wealth distribution simulation with multiple trackers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227974a6",
   "metadata": {},
   "source": [
    "## Game Rules\n",
    "\n",
    "### Start\n",
    "\n",
    "- Each player begins with a starting wealth of 1000.\n",
    "- Players can enter and exit the game at any time.\n",
    "- Players have a single active model they can update at any time. (here in the notebook , you create multiple local players)\n",
    "\n",
    "### Prediction Phase\n",
    "\n",
    "- For each prediction round, players automatically invest a fraction of their active wealth into the pot.\n",
    "- This amount is subtracted from their active wealth.\n",
    "- The total pot is inflated slightly by a game-defined inflation rate.\n",
    "- The model must generate predictions in under 50 Milliseconds.\n",
    "\n",
    "### Scoring & Distribution\n",
    "\n",
    "- Once the true dove location is revealed, each prediction is scored using a likelihood function.\n",
    "- The pot is then distributed proportionally based on these likelihood scores.\n",
    "- More accurate predictions earn a larger share of the pot.\n",
    "- Player wealth will never go below 0.\n",
    "- Players can skip predictions. Doing so means they cannot lose or gain wealth, as they are not participating in prize distribution. \n",
    "\n",
    "### Payouts\n",
    "\n",
    "- When a player’s wealth exceeds a defined wealth threshold of 2000, they receive a prize payout equal to 10% of their wealth.\n",
    "- This payout is treated like a withdrawal: it’s subtracted from their active wealth and moved to Realized Wealth.\n",
    "\n",
    "See full game rules in [Falcon](https://hub.crunchdao.com/competitions/falcon) challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Birdgame package imports\n",
    "from birdgame.trackers.trackerbase import TrackerBase\n",
    "from birdgame import HORIZON\n",
    "from birdgame import GAME_PARAMS\n",
    "\n",
    "from birdgame.datasources.livedata import live_data_generator\n",
    "from birdgame.datasources.remotetestdata import remote_test_data_generator\n",
    "from birdgame.trackers.tracker_evaluator import TrackerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birdgame Trackers\n",
    "from birdgame.examples.derived.ewmatracker import EMWAVarTracker\n",
    "# from birdgame.examples.derived.autoetstracker import AutoETSsktimeTracker\n",
    "# from birdgame.examples.derived.ngboosttracker import NGBoostTracker\n",
    "from birdgame.examples.derived.quantileregtracker import QuantileRegressionRiverTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91836f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-stationary starting autoregressive parameters\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-invertible starting MA parameters found\")\n",
    "\n",
    "# Parameters\n",
    "class Constants:\n",
    "    MIN_SAMPLES = 5\n",
    "    TRAIN_MODEL_FREQUENCY=50\n",
    "    NUM_DATA_POINTS_MAX=20\n",
    "    WARMUP_CUTOFF=200\n",
    "    USE_THREADING=True # Set this to True for live data streams where each `tick()` and `predict()` call must complete within ~50 ms\n",
    "\n",
    "class CustomTracker(TrackerBase):\n",
    "    \"\"\"\n",
    "    A model that tracks the dove location using AutoETS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    horizon : int\n",
    "        The prediction horizon in seconds (how far into the future predictions should be made).\n",
    "    train_model_frequency : int\n",
    "        The frequency at which the sktime model will be retrained based on the count of observations \n",
    "        ingested. This determines how often the model will be updated with new data.\n",
    "    num_data_points_max : int\n",
    "        The maximum number of data points to use for training the sktime model.\n",
    "    warmup : int\n",
    "        The number of ticks taken to warm up the model (wealth does not change during this period).\n",
    "    use_threading : bool\n",
    "        Whether to retrain the model asynchronously in a background thread.  \n",
    "        /!/ Set this to True for live data streams where each `tick()`  \n",
    "        and `predict()` call must complete within ~50 ms.  \n",
    "        When enabled, retraining happens in parallel without blocking predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, horizon=HORIZON):\n",
    "        super().__init__(horizon)\n",
    "        self.current_x = None\n",
    "        self.last_observed_data = [] # Holds the last few observed data points\n",
    "        self.prev_t = 0\n",
    "\n",
    "        self.min_samples = Constants.MIN_SAMPLES\n",
    "        self.train_model_frequency = Constants.TRAIN_MODEL_FREQUENCY\n",
    "        self.num_data_points_max = Constants.NUM_DATA_POINTS_MAX\n",
    "\n",
    "        # Number of steps to predict\n",
    "        steps = 1 # only one because the univariate serie will only have values separated of at least HORIZON time\n",
    "        self.fh = np.arange(1, steps + 1)\n",
    "\n",
    "        # Fit the AutoETS forecaster (no seasonality)\n",
    "        self.forecaster = AutoETS(auto=True, sp=1, information_criterion=\"aic\")\n",
    "        self.scale = 1e-6\n",
    "\n",
    "        # or Fit the AutoARIMA forecaster\n",
    "        # self.forecaster = AutoARIMA(max_p=2, max_d=1, max_q=2, maxiter=10)\n",
    "\n",
    "        self.warmup_cutoff = Constants.WARMUP_CUTOFF\n",
    "        self.tick_count = 0\n",
    "\n",
    "        # Threading tools\n",
    "        self.use_threading = Constants.USE_THREADING\n",
    "        self._lock = threading.Lock()\n",
    "        if self.use_threading:\n",
    "            self._cond = threading.Condition(self._lock)\n",
    "            self._new_data = None\n",
    "            self._stop_worker = False\n",
    "            self._worker_thread = threading.Thread(target=self._worker_retrain_model_async, daemon=True)\n",
    "            self._worker_thread.start()\n",
    "\n",
    "    # ------------------- Tick -------------------\n",
    "    def tick(self, payload, performance_metrics=None):\n",
    "        \"\"\"\n",
    "        Ingest a new record (payload), store it internally and update the model.\n",
    "\n",
    "        Function signature can also look like tick(self, payload) since performance_metrics \n",
    "        is an optional parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        payload : dict\n",
    "            Must contain 'time' (int/float) and 'dove_location' (float).\n",
    "        performance_metrics : dict (is optional)\n",
    "            Dict containing 'wealth', 'likelihood_ewa', 'recent_likelihood_ewa'.\n",
    "        \"\"\"\n",
    "        # # To see the performance metrics on each tick\n",
    "        # print(f\"performance_metrics: {performance_metrics}\")\n",
    "\n",
    "        # # Can also trigger a warmup by checking if a performance metric drops below a threshold\n",
    "        # if performance_metrics['recent_likelihood_ewa'] < 1.1:\n",
    "        #     self.tick_count = 0\n",
    "        \n",
    "        x = payload[\"dove_location\"]\n",
    "        t = payload[\"time\"]\n",
    "        self.add_to_quarantine(t, x)\n",
    "        self.current_x = x\n",
    "\n",
    "        # Collect and process observations only at horizon-based intervals\n",
    "        if t > self.prev_t + self.horizon:\n",
    "            self.last_observed_data.append(x)\n",
    "            self.prev_t = t\n",
    "\n",
    "            if self.count == self.min_samples or (self.count > self.min_samples and self.count % self.train_model_frequency == 0):\n",
    "                # Construct 'y' as an univariate serie\n",
    "                y = np.array(self.last_observed_data)[-self.num_data_points_max:]\n",
    "\n",
    "                # Fit sktime model and variance prediction\n",
    "                if self.use_threading:\n",
    "                    # Signal background thread\n",
    "                    with self._cond:\n",
    "                        self._new_data = y\n",
    "                        self._cond.notify()\n",
    "                else:\n",
    "                    self._retrain_model_sync(y)\n",
    "\n",
    "                # Update last observed data (to limit memory usage as it will be run on continuous live data)\n",
    "                self.last_observed_data = self.last_observed_data[-(self.num_data_points_max + 2):]\n",
    "\n",
    "            self.count += 1\n",
    "\n",
    "        self.tick_count += 1\n",
    "\n",
    "    # ------------------- Prediction -------------------\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary representing the best guess of the distribution,\n",
    "        modeled as a Gaussian distribution.\n",
    "\n",
    "        If the model is in the warmup period, return None.\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            # Check if the model is warming up\n",
    "            if self.tick_count < self.warmup_cutoff or self.forecaster is None:\n",
    "                return None\n",
    "\n",
    "            # the central value (mean) of the gaussian distribution will be represented by the current value\n",
    "            # but you can get point forecast from 'self.forecaster.predict(fh=self.fh[-1])[0][0]'\n",
    "            loc = self.current_x\n",
    "            # we predicted scale during tick training\n",
    "            scale = max(getattr(self, \"scale\", 1e-6), 1e-6)\n",
    "\n",
    "        # time.sleep(0.01)  # mimic short inference delay\n",
    "\n",
    "        # Return the prediction density\n",
    "        components = {\n",
    "            \"density\": {\n",
    "                \"type\": \"builtin\",\n",
    "                \"name\": \"norm\",\n",
    "                \"params\": {\"loc\": loc, \"scale\": scale},\n",
    "            },\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "\n",
    "        return {\"type\": \"mixture\", \"components\": [components]}\n",
    "\n",
    "    # ------------------- Model training -------------------\n",
    "    def _fit(self, y):\n",
    "        # Fit a clone sktime model (at least a cloned model is required in case of asynchronous training)\n",
    "        new_forecaster = self.forecaster.clone()\n",
    "        new_forecaster.fit(y, fh=self.fh)\n",
    "        # Variance prediction\n",
    "        var = new_forecaster.predict_var(fh=self.fh)\n",
    "        scale = np.sqrt(var.values.flatten()[-1])\n",
    "\n",
    "        return new_forecaster, scale\n",
    "\n",
    "    def _retrain_model_sync(self, y):\n",
    "        \"\"\"Synchronous retraining\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        self.forecaster, self.scale = self._fit(y)\n",
    "        # print(f\"Sync retrain time: {(time.perf_counter()- start_time)*1000:.2f} ms\") # check training time\n",
    "\n",
    "    def _worker_retrain_model_async(self):\n",
    "        \"\"\"Asynchronous retraining in a background worker\"\"\"\n",
    "        while True:\n",
    "            with self._cond:\n",
    "                # Wait until new data is available\n",
    "                while self._new_data is None:\n",
    "                    self._cond.wait()\n",
    "                y = self._new_data  # get the data to train on\n",
    "                self._new_data = None  # clear it (so next signal is new data)\n",
    "\n",
    "            # Train the model outside the lock (so predict() can still run)\n",
    "            new_forecaster, scale = self._fit(y)\n",
    "\n",
    "            # Swap the trained model safely\n",
    "            with self._lock:\n",
    "                self.forecaster = new_forecaster\n",
    "                self.scale = scale\n",
    "            # print(\"Async retraining done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1b4690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "LIVE_MODE = True   # Do not use threading if you set LIVE_MODE = False\n",
    "MAX_ROWS = None\n",
    "\n",
    "WARMUP_STEPS_ALL_MODELS = 500           # delay before updating wealth\n",
    "LOG_EVERY_N_STEPS = 100                 # print wealth info every N steps\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(message)s\")\n",
    "\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(evaluator, payload):\n",
    "    \"\"\"Safely tick and return the latest likelihood.\"\"\"\n",
    "    try:\n",
    "        evaluator.tick_and_predict(payload, {})\n",
    "        if evaluator.scores:\n",
    "            return evaluator.scores[-1]\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error during likelihood computation: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def update_wealth(players, likelihoods, params):\n",
    "    \"\"\"Update each player's wealth based on likelihood and shared pot.\"\"\"\n",
    "    valid_likelihoods = {k: v for k, v in likelihoods.items() if v is not None}\n",
    "    total_likelihood = sum(valid_likelihoods.values())\n",
    "\n",
    "    if not valid_likelihoods or total_likelihood == 0:\n",
    "        return\n",
    "\n",
    "    # Investment phase\n",
    "    pot = 0.0\n",
    "    for player in players.values():\n",
    "        investment = params[\"investment_fraction\"] * player[\"wealth\"]\n",
    "        player[\"wealth\"] = max(0.0, player[\"wealth\"] - investment)\n",
    "        pot += investment\n",
    "\n",
    "    # Inflation adjustment\n",
    "    pot *= 1 + params[\"inflation_bps\"] / 10000.0\n",
    "\n",
    "    # Redistribution phase\n",
    "    for name, likelihood in valid_likelihoods.items():\n",
    "        share = likelihood / total_likelihood\n",
    "        players[name][\"wealth\"] += pot * share\n",
    "\n",
    "\n",
    "def run_simulation_wealth(trackers, live=LIVE_MODE, max_rows=MAX_ROWS, game_params=GAME_PARAMS,\n",
    "                          warmup_steps_all_models=WARMUP_STEPS_ALL_MODELS, log_every_n_steps=LOG_EVERY_N_STEPS):\n",
    "    \"\"\"\n",
    "    Run the live or remote wealth distribution simulation with multiple trackers.\n",
    "\n",
    "    fading_factor : list\n",
    "        A list of trackers\n",
    "    \"\"\"\n",
    "    gen = live_data_generator() if live else remote_test_data_generator(max_rows=max_rows)\n",
    "    evaluators = {t.__class__.__name__: TrackerEvaluator(t) for t in trackers}\n",
    "\n",
    "    # Player setup\n",
    "    players = {\n",
    "        name: {\n",
    "            \"tracker_evaluator\": evaluator,\n",
    "            \"wealth\": game_params[\"initial_wealth\"],\n",
    "        }\n",
    "        for name, evaluator in evaluators.items()\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        for i, payload in enumerate(tqdm(gen)):\n",
    "            likelihoods = {\n",
    "                name: compute_likelihood(p[\"tracker_evaluator\"], payload)\n",
    "                for name, p in players.items()\n",
    "            }\n",
    "\n",
    "            # Only start wealth updates after a warmup period\n",
    "            if i > warmup_steps_all_models and not any(v is None for v in likelihoods.values()):\n",
    "                update_wealth(players, likelihoods, game_params)\n",
    "\n",
    "                if i % log_every_n_steps == 0:\n",
    "                    snapshot = {name: round(p[\"wealth\"], 2) for name, p in players.items()}\n",
    "                    logging.info(f\"Step {i:05d} | Wealth: {snapshot}\")\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "            print(\"Interrupted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd31a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9885670c8742f7bbce0ec718bac802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-23 17:06:53,590] Step 00600 | Wealth: {'EMWAVarTracker': 1122.7, 'QuantileRegressionRiverTracker': 947.87, 'CustomTracker': 929.46}\n",
      "[2025-10-23 17:06:56,742] Step 00700 | Wealth: {'EMWAVarTracker': 1145.28, 'QuantileRegressionRiverTracker': 866.21, 'CustomTracker': 988.57}\n",
      "[2025-10-23 17:07:00,967] Step 00800 | Wealth: {'EMWAVarTracker': 1103.52, 'QuantileRegressionRiverTracker': 855.8, 'CustomTracker': 1040.77}\n",
      "[2025-10-23 17:07:05,007] Step 00900 | Wealth: {'EMWAVarTracker': 1094.27, 'QuantileRegressionRiverTracker': 779.92, 'CustomTracker': 1125.93}\n",
      "[2025-10-23 17:07:11,663] Step 01000 | Wealth: {'EMWAVarTracker': 1151.69, 'QuantileRegressionRiverTracker': 710.08, 'CustomTracker': 1138.38}\n",
      "[2025-10-23 17:07:16,068] Step 01100 | Wealth: {'EMWAVarTracker': 1159.68, 'QuantileRegressionRiverTracker': 642.48, 'CustomTracker': 1198.03}\n",
      "[2025-10-23 17:07:21,989] Step 01200 | Wealth: {'EMWAVarTracker': 1164.11, 'QuantileRegressionRiverTracker': 662.97, 'CustomTracker': 1173.13}\n",
      "[2025-10-23 17:07:25,356] Step 01300 | Wealth: {'EMWAVarTracker': 1124.51, 'QuantileRegressionRiverTracker': 636.71, 'CustomTracker': 1239.01}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "trackers = [\n",
    "        EMWAVarTracker(),\n",
    "        QuantileRegressionRiverTracker(),\n",
    "        CustomTracker(),   # here: AutoETS quickstarter\n",
    "    ]\n",
    "\n",
    "run_simulation_wealth(trackers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
