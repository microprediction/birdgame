{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91566d3",
   "metadata": {},
   "source": [
    "# Run the wealth distribution simulation with multiple trackers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227974a6",
   "metadata": {},
   "source": [
    "## Game Rules\n",
    "\n",
    "### Start\n",
    "\n",
    "- Each player begins with a starting wealth of 1000.\n",
    "- Players can enter and exit the game at any time.\n",
    "- Players have a single active model they can update at any time. (here in the notebook , you create multiple local players)\n",
    "\n",
    "### Prediction Phase\n",
    "\n",
    "- For each prediction round, players automatically invest a fraction of their active wealth into the pot.\n",
    "- This amount is subtracted from their active wealth.\n",
    "- The total pot is inflated slightly by a game-defined inflation rate.\n",
    "- The model must generate predictions in under 50 Milliseconds.\n",
    "\n",
    "### Scoring & Distribution\n",
    "\n",
    "- Once the true dove location is revealed, each prediction is scored using a likelihood function.\n",
    "- The pot is then distributed proportionally based on these likelihood scores.\n",
    "- More accurate predictions earn a larger share of the pot.\n",
    "- Player wealth will never go below 0.\n",
    "- Players can skip predictions. Doing so means they cannot lose or gain wealth, as they are not participating in prize distribution. \n",
    "\n",
    "### Payouts\n",
    "\n",
    "- When a player’s wealth exceeds a defined wealth threshold of 2000, they receive a prize payout equal to 10% of their wealth.\n",
    "- This payout is treated like a withdrawal: it’s subtracted from their active wealth and moved to Realized Wealth.\n",
    "\n",
    "See full game rules in [Falcon](https://hub.crunchdao.com/competitions/falcon) challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72c1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Birdgame package imports\n",
    "from birdgame.trackers.trackerbase import TrackerBase\n",
    "from birdgame import HORIZON\n",
    "from birdgame import GAME_PARAMS\n",
    "\n",
    "from birdgame.datasources.livedata import live_data_generator\n",
    "from birdgame.datasources.remotetestdata import remote_test_data_generator\n",
    "from birdgame.trackers.tracker_evaluator import TrackerEvaluator\n",
    "\n",
    "from birdgame.wealth.wealth_mechanism import update_wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birdgame Trackers\n",
    "from birdgame.examples.derived.ewmatracker import EMWAVarTracker\n",
    "# from birdgame.examples.derived.autoetstracker import AutoETSsktimeTracker\n",
    "# from birdgame.examples.derived.ngboosttracker import NGBoostTracker\n",
    "from birdgame.examples.derived.quantileregtracker import QuantileRegressionRiverTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdddd7f",
   "metadata": {},
   "source": [
    "## Custom Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91836f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-stationary starting autoregressive parameters\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-invertible starting MA parameters found\")\n",
    "\n",
    "# Parameters\n",
    "class Constants:\n",
    "    MIN_SAMPLES = 5\n",
    "    TRAIN_MODEL_FREQUENCY=50\n",
    "    NUM_DATA_POINTS_MAX=20\n",
    "    WARMUP_CUTOFF=200\n",
    "    USE_THREADING=True # Set this to True for live data streams where each `tick()` and `predict()` call must complete within ~50 ms\n",
    "\n",
    "class CustomTracker(TrackerBase):\n",
    "    \"\"\"\n",
    "    A model that tracks the dove location using AutoETS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    horizon : int\n",
    "        The prediction horizon in seconds (how far into the future predictions should be made).\n",
    "    train_model_frequency : int\n",
    "        The frequency at which the sktime model will be retrained based on the count of observations \n",
    "        ingested. This determines how often the model will be updated with new data.\n",
    "    num_data_points_max : int\n",
    "        The maximum number of data points to use for training the sktime model.\n",
    "    warmup : int\n",
    "        The number of ticks taken to warm up the model (wealth does not change during this period).\n",
    "    use_threading : bool\n",
    "        Whether to retrain the model asynchronously in a background thread.  \n",
    "        /!/ Set this to True for live data streams where each `tick()`  \n",
    "        and `predict()` call must complete within ~50 ms.  \n",
    "        When enabled, retraining happens in parallel without blocking predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, horizon=HORIZON):\n",
    "        super().__init__(horizon)\n",
    "        self.current_x = None\n",
    "        self.last_observed_data = [] # Holds the last few observed data points\n",
    "        self.prev_t = 0\n",
    "\n",
    "        self.min_samples = Constants.MIN_SAMPLES\n",
    "        self.train_model_frequency = Constants.TRAIN_MODEL_FREQUENCY\n",
    "        self.num_data_points_max = Constants.NUM_DATA_POINTS_MAX\n",
    "\n",
    "        # Number of steps to predict\n",
    "        steps = 1 # only one because the univariate serie will only have values separated of at least HORIZON time\n",
    "        self.fh = np.arange(1, steps + 1)\n",
    "\n",
    "        # Fit the AutoETS forecaster (no seasonality)\n",
    "        self.forecaster = AutoETS(auto=True, sp=1, information_criterion=\"aic\")\n",
    "        self.scale = 1e-6\n",
    "\n",
    "        # or Fit the AutoARIMA forecaster\n",
    "        # self.forecaster = AutoARIMA(max_p=2, max_d=1, max_q=2, maxiter=10)\n",
    "\n",
    "        self.warmup_cutoff = Constants.WARMUP_CUTOFF\n",
    "        self.tick_count = 0\n",
    "\n",
    "        # Threading tools\n",
    "        self.use_threading = Constants.USE_THREADING\n",
    "        self._lock = threading.Lock()\n",
    "        if self.use_threading:\n",
    "            self._cond = threading.Condition(self._lock)\n",
    "            self._new_data = None\n",
    "            self._stop_worker = False\n",
    "            self._worker_thread = threading.Thread(target=self._worker_retrain_model_async, daemon=True)\n",
    "            self._worker_thread.start()\n",
    "\n",
    "    # ------------------- Tick -------------------\n",
    "    def tick(self, payload, performance_metrics=None):\n",
    "        \"\"\"\n",
    "        Ingest a new record (payload), store it internally and update the model.\n",
    "\n",
    "        Function signature can also look like tick(self, payload) since performance_metrics \n",
    "        is an optional parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        payload : dict\n",
    "            Must contain 'time' (int/float) and 'dove_location' (float).\n",
    "        performance_metrics : dict (is optional)\n",
    "            Dict containing 'wealth', 'likelihood_ewa', 'recent_likelihood_ewa'.\n",
    "        \"\"\"\n",
    "        # # To see the performance metrics on each tick\n",
    "        # print(f\"performance_metrics: {performance_metrics}\")\n",
    "\n",
    "        # # Can also trigger a warmup by checking if a performance metric drops below a threshold\n",
    "        # if performance_metrics['recent_likelihood_ewa'] < 1.1:\n",
    "        #     self.tick_count = 0\n",
    "        \n",
    "        x = payload[\"dove_location\"]\n",
    "        t = payload[\"time\"]\n",
    "        self.add_to_quarantine(t, x)\n",
    "        self.current_x = x\n",
    "\n",
    "        # Collect and process observations only at horizon-based intervals\n",
    "        if t > self.prev_t + self.horizon:\n",
    "            self.last_observed_data.append(x)\n",
    "            self.prev_t = t\n",
    "\n",
    "            if self.count == self.min_samples or (self.count > self.min_samples and self.count % self.train_model_frequency == 0):\n",
    "                # Construct 'y' as an univariate serie\n",
    "                y = np.array(self.last_observed_data)[-self.num_data_points_max:]\n",
    "\n",
    "                # Fit sktime model and variance prediction\n",
    "                if self.use_threading:\n",
    "                    # Signal background thread\n",
    "                    with self._cond:\n",
    "                        self._new_data = y\n",
    "                        self._cond.notify()\n",
    "                else:\n",
    "                    self._retrain_model_sync(y)\n",
    "\n",
    "                # Update last observed data (to limit memory usage as it will be run on continuous live data)\n",
    "                self.last_observed_data = self.last_observed_data[-(self.num_data_points_max + 2):]\n",
    "\n",
    "            self.count += 1\n",
    "\n",
    "        self.tick_count += 1\n",
    "\n",
    "    # ------------------- Prediction -------------------\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary representing the best guess of the distribution,\n",
    "        modeled as a Gaussian distribution.\n",
    "\n",
    "        If the model is in the warmup period, return None.\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            # Check if the model is warming up\n",
    "            if self.tick_count < self.warmup_cutoff or self.forecaster is None:\n",
    "                return None\n",
    "\n",
    "            # the central value (mean) of the gaussian distribution will be represented by the current value\n",
    "            # but you can get point forecast from 'self.forecaster.predict(fh=self.fh[-1])[0][0]'\n",
    "            loc = self.current_x\n",
    "            # we predicted scale during tick training\n",
    "            scale = max(getattr(self, \"scale\", 1e-6), 1e-6)\n",
    "\n",
    "        # time.sleep(0.01)  # mimic short inference delay\n",
    "\n",
    "        # Return the prediction density\n",
    "        components = {\n",
    "            \"density\": {\n",
    "                \"type\": \"builtin\",\n",
    "                \"name\": \"norm\",\n",
    "                \"params\": {\"loc\": loc, \"scale\": scale},\n",
    "            },\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "\n",
    "        return {\"type\": \"mixture\", \"components\": [components]}\n",
    "\n",
    "    # ------------------- Model training -------------------\n",
    "    def _fit(self, y):\n",
    "        # Fit a clone sktime model (at least a cloned model is required in case of asynchronous training)\n",
    "        new_forecaster = self.forecaster.clone()\n",
    "        new_forecaster.fit(y, fh=self.fh)\n",
    "        # Variance prediction\n",
    "        var = new_forecaster.predict_var(fh=self.fh)\n",
    "        scale = np.sqrt(var.values.flatten()[-1])\n",
    "\n",
    "        return new_forecaster, scale\n",
    "\n",
    "    def _retrain_model_sync(self, y):\n",
    "        \"\"\"Synchronous retraining\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        self.forecaster, self.scale = self._fit(y)\n",
    "        # print(f\"Sync retrain time: {(time.perf_counter()- start_time)*1000:.2f} ms\") # check training time\n",
    "\n",
    "    def _worker_retrain_model_async(self):\n",
    "        \"\"\"Asynchronous retraining in a background worker\"\"\"\n",
    "        while True:\n",
    "            with self._cond:\n",
    "                # Wait until new data is available\n",
    "                while self._new_data is None:\n",
    "                    self._cond.wait()\n",
    "                y = self._new_data  # get the data to train on\n",
    "                self._new_data = None  # clear it (so next signal is new data)\n",
    "\n",
    "            # Train the model outside the lock (so predict() can still run)\n",
    "            new_forecaster, scale = self._fit(y)\n",
    "\n",
    "            # Swap the trained model safely\n",
    "            with self._lock:\n",
    "                self.forecaster = new_forecaster\n",
    "                self.scale = scale\n",
    "            # print(\"Async retraining done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941a647",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIVE_MODE = True   # Do not use threading if you set LIVE_MODE = False\n",
    "MAX_ROWS = None\n",
    "\n",
    "WARMUP_STEPS_ALL_MODELS = 500           # delay for warmup of models\n",
    "WARMUP_STEPS_EWMA = 1000                # delay before wealth redistribution / skip redistribution to stabilize EWMA\n",
    "LOG_EVERY_N_STEPS = 100                 # print wealth info every N steps\n",
    "# FYI: 1000 steps/ticks ≃ 1min\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba676cf5",
   "metadata": {},
   "source": [
    "## Run wealth distribution simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(evaluator, payload):\n",
    "    \"\"\"Safely tick and return the latest likelihood.\"\"\"\n",
    "    try:\n",
    "        # - The model must generate predictions in under 50 Milliseconds.\n",
    "        evaluator.tick_and_predict(payload, {})\n",
    "        return evaluator.last_score\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error during likelihood computation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def run_simulation_wealth(trackers, live=LIVE_MODE, max_rows=MAX_ROWS, game_params=GAME_PARAMS,\n",
    "                          warmup_steps_all_models=WARMUP_STEPS_ALL_MODELS, warmup_steps_ewma=WARMUP_STEPS_EWMA,\n",
    "                          log_every_n_steps=LOG_EVERY_N_STEPS):\n",
    "    \"\"\"\n",
    "    Run the live or remote wealth distribution simulation with multiple trackers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trackers : list\n",
    "        List of tracker instances to evaluate.\n",
    "    live : bool\n",
    "        Whether to use live data or remote test data.\n",
    "    max_rows : int | None\n",
    "        Maximum rows to fetch from remote data generator.\n",
    "    game_params : dict\n",
    "        Dictionary with keys: 'initial_wealth', 'investment_fraction', 'inflation_bps'.\n",
    "    warmup_steps_all_models : int\n",
    "        Number of steps to warm up trackers.\n",
    "    warmup_steps_ewma : int\n",
    "        Number of steps before wealth redistribution (to stabilize EWMA)\n",
    "    log_every_n_steps : int\n",
    "        Logging frequency for wealth snapshots.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Updates player wealth over the simulation.\n",
    "    \"\"\"\n",
    "    gen = live_data_generator() if live else remote_test_data_generator(max_rows=max_rows)\n",
    "    evaluators = {t.__class__.__name__: TrackerEvaluator(t) for t in trackers}\n",
    "\n",
    "    # Player setup\n",
    "    players = {\n",
    "        name: {\n",
    "            \"tracker_evaluator\": evaluator,\n",
    "            \"wealth\": game_params[\"initial_wealth\"],\n",
    "        }\n",
    "        for name, evaluator in evaluators.items()\n",
    "    }\n",
    "\n",
    "    nb_update = 0  # count of updates skipped for EWMA warmup\n",
    "\n",
    "    try:\n",
    "        for i, payload in enumerate(tqdm(gen)):\n",
    "            likelihoods = {\n",
    "                name: compute_likelihood(p[\"tracker_evaluator\"], payload)\n",
    "                for name, p in players.items()\n",
    "            }\n",
    "\n",
    "            # Only start wealth updates after a warmup period\n",
    "            # (here for simplicity: we update wealth only if all models have valid likelihood)\n",
    "            if i > warmup_steps_all_models and not any(v is None for v in likelihoods.values()):\n",
    "                \n",
    "                # During first updates, skip redistribution to stabilize EWMA\n",
    "                if nb_update < warmup_steps_ewma:\n",
    "                    wealth_update = False\n",
    "                    nb_update += 1\n",
    "                else:\n",
    "                    wealth_update = True\n",
    "\n",
    "                update_wealth(players, likelihoods, game_params, wealth_update=wealth_update)\n",
    "\n",
    "                if i % log_every_n_steps == 0:\n",
    "                    snapshot = {name: round(p[\"wealth\"], 2) for name, p in players.items()}\n",
    "                    logging.info(f\"Step {i:05d} | Wealth: {snapshot}\")\n",
    "\n",
    "                    # snapshot_ewma = {name: players[name][\"ewma_blend_logL\"] for name in players}\n",
    "                    # logging.info(f\"Step {i:05d} | EWMA log-likelihood: {snapshot_ewma}\")\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd31a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53074a5d67404adc88590869beed4a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-06 15:14:30,617] Step 00600 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:14:30,619] Step 00600 | EWMA log-likelihood: {'EMWAVarTracker': 1.6634958003247986, 'QuantileRegressionRiverTracker': 1.5263565657626614, 'CustomTracker': -27.631021115928547}\n",
      "[2025-11-06 15:14:37,791] Step 00700 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:14:37,792] Step 00700 | EWMA log-likelihood: {'EMWAVarTracker': 1.722832080615385, 'QuantileRegressionRiverTracker': 1.6591279176525473, 'CustomTracker': -24.661827281968108}\n",
      "[2025-11-06 15:14:46,095] Step 00800 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:14:46,098] Step 00800 | EWMA log-likelihood: {'EMWAVarTracker': 1.7523921462573457, 'QuantileRegressionRiverTracker': 1.617494851086236, 'CustomTracker': -21.839294208769267}\n",
      "[2025-11-06 15:14:53,715] Step 00900 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:14:53,716] Step 00900 | EWMA log-likelihood: {'EMWAVarTracker': 1.8079285805431473, 'QuantileRegressionRiverTracker': 1.7176931379104934, 'CustomTracker': -19.246920226649863}\n",
      "[2025-11-06 15:15:01,878] Step 01000 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:01,879] Step 01000 | EWMA log-likelihood: {'EMWAVarTracker': -0.9699384237218265, 'QuantileRegressionRiverTracker': -1.0538033824398183, 'CustomTracker': -20.26343684435545}\n",
      "[2025-11-06 15:15:08,128] Step 01100 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:08,128] Step 01100 | EWMA log-likelihood: {'EMWAVarTracker': -2.659143940274037, 'QuantileRegressionRiverTracker': -2.8847629933381365, 'CustomTracker': -20.55869581896015}\n",
      "[2025-11-06 15:15:17,380] Step 01200 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:17,380] Step 01200 | EWMA log-likelihood: {'EMWAVarTracker': -1.5314839195011474, 'QuantileRegressionRiverTracker': -1.8575167007511237, 'CustomTracker': -18.77872929217985}\n",
      "[2025-11-06 15:15:25,048] Step 01300 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:25,050] Step 01300 | EWMA log-likelihood: {'EMWAVarTracker': -0.6953743456106085, 'QuantileRegressionRiverTracker': -0.9753913837430085, 'CustomTracker': -17.40544050118248}\n",
      "[2025-11-06 15:15:32,587] Step 01400 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:32,588] Step 01400 | EWMA log-likelihood: {'EMWAVarTracker': -0.08703018146797337, 'QuantileRegressionRiverTracker': -0.32729214697815, 'CustomTracker': -16.689942901116165}\n",
      "[2025-11-06 15:15:40,078] Step 01500 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-06 15:15:40,078] Step 01500 | EWMA log-likelihood: {'EMWAVarTracker': 0.3712642246252659, 'QuantileRegressionRiverTracker': 0.1097348991984145, 'CustomTracker': -16.007450735092746}\n",
      "[2025-11-06 15:15:47,727] Step 01600 | Wealth: {'EMWAVarTracker': 1007.1, 'QuantileRegressionRiverTracker': 1002.85, 'CustomTracker': 990.05}\n",
      "[2025-11-06 15:15:47,727] Step 01600 | EWMA log-likelihood: {'EMWAVarTracker': 0.7098150780642414, 'QuantileRegressionRiverTracker': 0.4576794911300329, 'CustomTracker': -15.538166478835027}\n",
      "[2025-11-06 15:15:55,610] Step 01700 | Wealth: {'EMWAVarTracker': 1013.83, 'QuantileRegressionRiverTracker': 1005.98, 'CustomTracker': 980.2}\n",
      "[2025-11-06 15:15:55,610] Step 01700 | EWMA log-likelihood: {'EMWAVarTracker': 0.9538665073970318, 'QuantileRegressionRiverTracker': 0.6678965645020988, 'CustomTracker': -15.328774918222521}\n",
      "[2025-11-06 15:16:03,326] Step 01800 | Wealth: {'EMWAVarTracker': 1020.33, 'QuantileRegressionRiverTracker': 1009.24, 'CustomTracker': 970.44}\n",
      "[2025-11-06 15:16:03,326] Step 01800 | EWMA log-likelihood: {'EMWAVarTracker': 1.175044386019437, 'QuantileRegressionRiverTracker': 1.0086171768252246, 'CustomTracker': -14.379405003193646}\n",
      "[2025-11-06 15:16:11,459] Step 01900 | Wealth: {'EMWAVarTracker': 1027.08, 'QuantileRegressionRiverTracker': 1012.15, 'CustomTracker': 960.79}\n",
      "[2025-11-06 15:16:11,459] Step 01900 | EWMA log-likelihood: {'EMWAVarTracker': 1.3170658848299133, 'QuantileRegressionRiverTracker': 0.860545139642553, 'CustomTracker': -14.120280647547634}\n",
      "[2025-11-06 15:16:19,509] Step 02000 | Wealth: {'EMWAVarTracker': 1034.93, 'QuantileRegressionRiverTracker': 1013.86, 'CustomTracker': 951.23}\n",
      "[2025-11-06 15:16:19,509] Step 02000 | EWMA log-likelihood: {'EMWAVarTracker': 1.4455012150201634, 'QuantileRegressionRiverTracker': 1.0730001438889811, 'CustomTracker': -13.517665163606942}\n",
      "[2025-11-06 15:16:28,142] Step 02100 | Wealth: {'EMWAVarTracker': 1041.76, 'QuantileRegressionRiverTracker': 1016.5, 'CustomTracker': 941.76}\n",
      "[2025-11-06 15:16:28,157] Step 02100 | EWMA log-likelihood: {'EMWAVarTracker': 1.5402887846684505, 'QuantileRegressionRiverTracker': 1.2433350836907318, 'CustomTracker': -13.112876324421082}\n",
      "[2025-11-06 15:16:35,767] Step 02200 | Wealth: {'EMWAVarTracker': 1049.36, 'QuantileRegressionRiverTracker': 1018.27, 'CustomTracker': 932.39}\n",
      "[2025-11-06 15:16:35,774] Step 02200 | EWMA log-likelihood: {'EMWAVarTracker': 1.6035478456944636, 'QuantileRegressionRiverTracker': 1.1637250529689884, 'CustomTracker': -12.962259014746264}\n",
      "[2025-11-06 15:16:43,427] Step 02300 | Wealth: {'EMWAVarTracker': 1060.99, 'QuantileRegressionRiverTracker': 1015.92, 'CustomTracker': 923.11}\n",
      "[2025-11-06 15:16:43,428] Step 02300 | EWMA log-likelihood: {'EMWAVarTracker': 1.4256406393471766, 'QuantileRegressionRiverTracker': -0.5946801506312729, 'CustomTracker': -15.270213114731595}\n",
      "[2025-11-06 15:16:51,439] Step 02400 | Wealth: {'EMWAVarTracker': 1075.86, 'QuantileRegressionRiverTracker': 1010.24, 'CustomTracker': 913.93}\n",
      "[2025-11-06 15:16:51,440] Step 02400 | EWMA log-likelihood: {'EMWAVarTracker': 1.4657768897289456, 'QuantileRegressionRiverTracker': -0.04704606625820018, 'CustomTracker': -15.335999306470718}\n",
      "[2025-11-06 15:16:59,962] Step 02500 | Wealth: {'EMWAVarTracker': 1088.71, 'QuantileRegressionRiverTracker': 1006.49, 'CustomTracker': 904.83}\n",
      "[2025-11-06 15:16:59,965] Step 02500 | EWMA log-likelihood: {'EMWAVarTracker': 1.5199487791344093, 'QuantileRegressionRiverTracker': 0.37458374444380116, 'CustomTracker': -15.03911693161625}\n",
      "[2025-11-06 15:17:07,095] Step 02600 | Wealth: {'EMWAVarTracker': 1099.64, 'QuantileRegressionRiverTracker': 1004.57, 'CustomTracker': 895.83}\n",
      "[2025-11-06 15:17:07,097] Step 02600 | EWMA log-likelihood: {'EMWAVarTracker': 1.596172815989556, 'QuantileRegressionRiverTracker': 0.7418922277951423, 'CustomTracker': -14.179849396942497}\n",
      "[2025-11-06 15:17:15,145] Step 02700 | Wealth: {'EMWAVarTracker': 1108.94, 'QuantileRegressionRiverTracker': 1004.18, 'CustomTracker': 886.92}\n",
      "[2025-11-06 15:17:15,145] Step 02700 | EWMA log-likelihood: {'EMWAVarTracker': 1.6487653367812802, 'QuantileRegressionRiverTracker': 1.0156664962691853, 'CustomTracker': -13.621283413623393}\n",
      "[2025-11-06 15:17:22,785] Step 02800 | Wealth: {'EMWAVarTracker': 1116.81, 'QuantileRegressionRiverTracker': 1005.14, 'CustomTracker': 878.09}\n",
      "[2025-11-06 15:17:22,786] Step 02800 | EWMA log-likelihood: {'EMWAVarTracker': 1.6748794381705487, 'QuantileRegressionRiverTracker': 1.0953481343978415, 'CustomTracker': -13.423182892075639}\n",
      "[2025-11-06 15:17:30,754] Step 02900 | Wealth: {'EMWAVarTracker': 1126.55, 'QuantileRegressionRiverTracker': 1004.14, 'CustomTracker': 869.35}\n",
      "[2025-11-06 15:17:30,755] Step 02900 | EWMA log-likelihood: {'EMWAVarTracker': 1.6285873371937047, 'QuantileRegressionRiverTracker': 0.6935578633589845, 'CustomTracker': -14.335213121153322}\n",
      "[2025-11-06 15:17:37,923] Step 03000 | Wealth: {'EMWAVarTracker': 1137.24, 'QuantileRegressionRiverTracker': 1002.1, 'CustomTracker': 860.7}\n",
      "[2025-11-06 15:17:37,923] Step 03000 | EWMA log-likelihood: {'EMWAVarTracker': 1.2841750377870789, 'QuantileRegressionRiverTracker': -0.1258129561272492, 'CustomTracker': -16.47550123191898}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "trackers = [\n",
    "        EMWAVarTracker(),\n",
    "        QuantileRegressionRiverTracker(),\n",
    "        CustomTracker(),   # here: AutoETS quickstarter\n",
    "    ]\n",
    "\n",
    "run_simulation_wealth(trackers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
