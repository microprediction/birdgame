{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91566d3",
   "metadata": {},
   "source": [
    "# Run the wealth distribution simulation with multiple trackers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227974a6",
   "metadata": {},
   "source": [
    "## Game Rules\n",
    "\n",
    "### Start\n",
    "\n",
    "- Each player begins with a starting wealth of 1000.\n",
    "- Players can enter and exit the game at any time.\n",
    "- Players have a single active model they can update at any time. (here in the notebook , you create multiple local players)\n",
    "\n",
    "### Prediction Phase\n",
    "\n",
    "- For each prediction round, players automatically invest a fraction of their active wealth into the pot.\n",
    "- This amount is subtracted from their active wealth.\n",
    "- The total pot is inflated slightly by a game-defined inflation rate.\n",
    "- The model must generate predictions in under 50 Milliseconds.\n",
    "\n",
    "### Scoring & Distribution\n",
    "\n",
    "- Once the true dove location is revealed, each prediction is scored using a likelihood function.\n",
    "- The pot is then distributed proportionally based on these likelihood scores.\n",
    "- More accurate predictions earn a larger share of the pot.\n",
    "- Player wealth will never go below 0.\n",
    "- Players can skip predictions. Doing so means they cannot lose or gain wealth, as they are not participating in prize distribution. \n",
    "\n",
    "### Payouts\n",
    "\n",
    "- When a player’s wealth exceeds a defined wealth threshold of 2000, they receive a prize payout equal to 10% of their wealth.\n",
    "- This payout is treated like a withdrawal: it’s subtracted from their active wealth and moved to Realized Wealth.\n",
    "\n",
    "See full game rules in [Falcon](https://hub.crunchdao.com/competitions/falcon) challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72c1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Birdgame package imports\n",
    "from birdgame.trackers.trackerbase import TrackerBase\n",
    "from birdgame import HORIZON\n",
    "from birdgame import GAME_PARAMS\n",
    "\n",
    "from birdgame.datasources.livedata import live_data_generator\n",
    "from birdgame.datasources.remotetestdata import remote_test_data_generator\n",
    "from birdgame.trackers.tracker_evaluator import TrackerEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0e4f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birdgame Trackers\n",
    "from birdgame.examples.derived.ewmatracker import EMWAVarTracker\n",
    "# from birdgame.examples.derived.autoetstracker import AutoETSsktimeTracker\n",
    "# from birdgame.examples.derived.ngboosttracker import NGBoostTracker\n",
    "from birdgame.examples.derived.quantileregtracker import QuantileRegressionRiverTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdddd7f",
   "metadata": {},
   "source": [
    "## Custom Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91836f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import warnings\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress convergence warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-stationary starting autoregressive parameters\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Non-invertible starting MA parameters found\")\n",
    "\n",
    "# Parameters\n",
    "class Constants:\n",
    "    MIN_SAMPLES = 5\n",
    "    TRAIN_MODEL_FREQUENCY=50\n",
    "    NUM_DATA_POINTS_MAX=20\n",
    "    WARMUP_CUTOFF=200\n",
    "    USE_THREADING=True # Set this to True for live data streams where each `tick()` and `predict()` call must complete within ~50 ms\n",
    "\n",
    "class CustomTracker(TrackerBase):\n",
    "    \"\"\"\n",
    "    A model that tracks the dove location using AutoETS.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    horizon : int\n",
    "        The prediction horizon in seconds (how far into the future predictions should be made).\n",
    "    train_model_frequency : int\n",
    "        The frequency at which the sktime model will be retrained based on the count of observations \n",
    "        ingested. This determines how often the model will be updated with new data.\n",
    "    num_data_points_max : int\n",
    "        The maximum number of data points to use for training the sktime model.\n",
    "    warmup : int\n",
    "        The number of ticks taken to warm up the model (wealth does not change during this period).\n",
    "    use_threading : bool\n",
    "        Whether to retrain the model asynchronously in a background thread.  \n",
    "        /!/ Set this to True for live data streams where each `tick()`  \n",
    "        and `predict()` call must complete within ~50 ms.  \n",
    "        When enabled, retraining happens in parallel without blocking predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, horizon=HORIZON):\n",
    "        super().__init__(horizon)\n",
    "        self.current_x = None\n",
    "        self.last_observed_data = [] # Holds the last few observed data points\n",
    "        self.prev_t = 0\n",
    "\n",
    "        self.min_samples = Constants.MIN_SAMPLES\n",
    "        self.train_model_frequency = Constants.TRAIN_MODEL_FREQUENCY\n",
    "        self.num_data_points_max = Constants.NUM_DATA_POINTS_MAX\n",
    "\n",
    "        # Number of steps to predict\n",
    "        steps = 1 # only one because the univariate serie will only have values separated of at least HORIZON time\n",
    "        self.fh = np.arange(1, steps + 1)\n",
    "\n",
    "        # Fit the AutoETS forecaster (no seasonality)\n",
    "        self.forecaster = AutoETS(auto=True, sp=1, information_criterion=\"aic\")\n",
    "        self.scale = 1e-6\n",
    "\n",
    "        # or Fit the AutoARIMA forecaster\n",
    "        # self.forecaster = AutoARIMA(max_p=2, max_d=1, max_q=2, maxiter=10)\n",
    "\n",
    "        self.warmup_cutoff = Constants.WARMUP_CUTOFF\n",
    "        self.tick_count = 0\n",
    "\n",
    "        # Threading tools\n",
    "        self.use_threading = Constants.USE_THREADING\n",
    "        self._lock = threading.Lock()\n",
    "        if self.use_threading:\n",
    "            self._cond = threading.Condition(self._lock)\n",
    "            self._new_data = None\n",
    "            self._stop_worker = False\n",
    "            self._worker_thread = threading.Thread(target=self._worker_retrain_model_async, daemon=True)\n",
    "            self._worker_thread.start()\n",
    "\n",
    "    # ------------------- Tick -------------------\n",
    "    def tick(self, payload, performance_metrics=None):\n",
    "        \"\"\"\n",
    "        Ingest a new record (payload), store it internally and update the model.\n",
    "\n",
    "        Function signature can also look like tick(self, payload) since performance_metrics \n",
    "        is an optional parameter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        payload : dict\n",
    "            Must contain 'time' (int/float) and 'dove_location' (float).\n",
    "        performance_metrics : dict (is optional)\n",
    "            Dict containing 'wealth', 'likelihood_ewa', 'recent_likelihood_ewa'.\n",
    "        \"\"\"\n",
    "        # # To see the performance metrics on each tick\n",
    "        # print(f\"performance_metrics: {performance_metrics}\")\n",
    "\n",
    "        # # Can also trigger a warmup by checking if a performance metric drops below a threshold\n",
    "        # if performance_metrics['recent_likelihood_ewa'] < 1.1:\n",
    "        #     self.tick_count = 0\n",
    "        \n",
    "        x = payload[\"dove_location\"]\n",
    "        t = payload[\"time\"]\n",
    "        self.add_to_quarantine(t, x)\n",
    "        self.current_x = x\n",
    "\n",
    "        # Collect and process observations only at horizon-based intervals\n",
    "        if t > self.prev_t + self.horizon:\n",
    "            self.last_observed_data.append(x)\n",
    "            self.prev_t = t\n",
    "\n",
    "            if self.count == self.min_samples or (self.count > self.min_samples and self.count % self.train_model_frequency == 0):\n",
    "                # Construct 'y' as an univariate serie\n",
    "                y = np.array(self.last_observed_data)[-self.num_data_points_max:]\n",
    "\n",
    "                # Fit sktime model and variance prediction\n",
    "                if self.use_threading:\n",
    "                    # Signal background thread\n",
    "                    with self._cond:\n",
    "                        self._new_data = y\n",
    "                        self._cond.notify()\n",
    "                else:\n",
    "                    self._retrain_model_sync(y)\n",
    "\n",
    "                # Update last observed data (to limit memory usage as it will be run on continuous live data)\n",
    "                self.last_observed_data = self.last_observed_data[-(self.num_data_points_max + 2):]\n",
    "\n",
    "            self.count += 1\n",
    "\n",
    "        self.tick_count += 1\n",
    "\n",
    "    # ------------------- Prediction -------------------\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary representing the best guess of the distribution,\n",
    "        modeled as a Gaussian distribution.\n",
    "\n",
    "        If the model is in the warmup period, return None.\n",
    "        \"\"\"\n",
    "        with self._lock:\n",
    "            # Check if the model is warming up\n",
    "            if self.tick_count < self.warmup_cutoff or self.forecaster is None:\n",
    "                return None\n",
    "\n",
    "            # the central value (mean) of the gaussian distribution will be represented by the current value\n",
    "            # but you can get point forecast from 'self.forecaster.predict(fh=self.fh[-1])[0][0]'\n",
    "            loc = self.current_x\n",
    "            # we predicted scale during tick training\n",
    "            scale = max(getattr(self, \"scale\", 1e-6), 1e-6)\n",
    "\n",
    "        # time.sleep(0.01)  # mimic short inference delay\n",
    "\n",
    "        # Return the prediction density\n",
    "        components = {\n",
    "            \"density\": {\n",
    "                \"type\": \"builtin\",\n",
    "                \"name\": \"norm\",\n",
    "                \"params\": {\"loc\": loc, \"scale\": scale},\n",
    "            },\n",
    "            \"weight\": 1,\n",
    "        }\n",
    "\n",
    "        return {\"type\": \"mixture\", \"components\": [components]}\n",
    "\n",
    "    # ------------------- Model training -------------------\n",
    "    def _fit(self, y):\n",
    "        # Fit a clone sktime model (at least a cloned model is required in case of asynchronous training)\n",
    "        new_forecaster = self.forecaster.clone()\n",
    "        new_forecaster.fit(y, fh=self.fh)\n",
    "        # Variance prediction\n",
    "        var = new_forecaster.predict_var(fh=self.fh)\n",
    "        scale = np.sqrt(var.values.flatten()[-1])\n",
    "\n",
    "        return new_forecaster, scale\n",
    "\n",
    "    def _retrain_model_sync(self, y):\n",
    "        \"\"\"Synchronous retraining\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        self.forecaster, self.scale = self._fit(y)\n",
    "        # print(f\"Sync retrain time: {(time.perf_counter()- start_time)*1000:.2f} ms\") # check training time\n",
    "\n",
    "    def _worker_retrain_model_async(self):\n",
    "        \"\"\"Asynchronous retraining in a background worker\"\"\"\n",
    "        while True:\n",
    "            with self._cond:\n",
    "                # Wait until new data is available\n",
    "                while self._new_data is None:\n",
    "                    self._cond.wait()\n",
    "                y = self._new_data  # get the data to train on\n",
    "                self._new_data = None  # clear it (so next signal is new data)\n",
    "\n",
    "            # Train the model outside the lock (so predict() can still run)\n",
    "            new_forecaster, scale = self._fit(y)\n",
    "\n",
    "            # Swap the trained model safely\n",
    "            with self._lock:\n",
    "                self.forecaster = new_forecaster\n",
    "                self.scale = scale\n",
    "            # print(\"Async retraining done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941a647",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b4690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIVE_MODE = True   # Do not use threading if you set LIVE_MODE = False ## LIVE_MODE = True available only from Sunday 22:00 UTC to Friday 22:00 UTC\n",
    "MAX_ROWS = None\n",
    "\n",
    "WARMUP_STEPS_ALL_MODELS = 500           # delay before updating wealth\n",
    "LOG_EVERY_N_STEPS = 100                 # print wealth info every N steps\n",
    "\n",
    "ALPHA = 0.001            # Smoothing factor for exponentially weighted moving average of log-likelihood\n",
    "EWMA_WEIGHT = 0.5        # Weighting factor to blend instantaneous likelihood vs EWMA for wealth redistribution\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba676cf5",
   "metadata": {},
   "source": [
    "## Run wealth distribution simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(evaluator, payload):\n",
    "    \"\"\"Safely tick and return the latest likelihood.\"\"\"\n",
    "    try:\n",
    "        # - The model must generate predictions in under 50 Milliseconds.\n",
    "        evaluator.tick_and_predict(payload, {})\n",
    "        return evaluator.last_score\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error during likelihood computation: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def update_wealth(players, likelihoods, params, alpha=ALPHA, ewma_weight=EWMA_WEIGHT, wealth_update=True):\n",
    "    \"\"\"\n",
    "    Update each player's wealth using a combination of instantaneous likelihood\n",
    "    and exponentially weighted moving average (EWMA) of log-likelihood.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    players : dict\n",
    "        Dictionary of player states. Each player must have 'wealth' and optionally 'ewma_logL'.\n",
    "    likelihoods : dict\n",
    "        Instantaneous likelihood scores from the current tick for each player.\n",
    "    params : dict\n",
    "        Game parameters including 'investment_fraction' and 'inflation_bps'.\n",
    "    alpha : float\n",
    "        Smoothing factor for EWMA of log-likelihood.\n",
    "    ewma_weight : float\n",
    "        Weight assigned to the long-term EWMA component when computing wealth share.\n",
    "        (1-ewma_weight is given to instantaneous likelihood)\n",
    "    wealth_update : bool\n",
    "        If False, skip the wealth update (used for warming up the EWMA statistics).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Updates `players` in place.\n",
    "    \"\"\"\n",
    "    valid_likelihoods = {k: v for k, v in likelihoods.items() if v is not None}\n",
    "    if not valid_likelihoods:\n",
    "        return\n",
    "\n",
    "    # --- Update EWMA log-likelihood for each player ---\n",
    "    for name, likelihood in valid_likelihoods.items():\n",
    "        player = players[name]\n",
    "        log_likelihood = math.log(max(likelihood, 1e-12))\n",
    "\n",
    "        if \"ewma_logL\" not in player:\n",
    "            # Initialize EWMA with first log-likelihood\n",
    "            player[\"ewma_logL\"] = log_likelihood\n",
    "        else:\n",
    "            # Update EWMA\n",
    "            player[\"ewma_logL\"] = alpha * log_likelihood + (1 - alpha) * player[\"ewma_logL\"]\n",
    "\n",
    "    # --- Compute normalized EWMA weights ---\n",
    "    ewmas = {name: players[name][\"ewma_logL\"] for name in valid_likelihoods}\n",
    "    max_ewma = max(ewmas.values())\n",
    "    rel_ewma = {name: math.exp(ewmas[name] - max_ewma) for name in ewmas}\n",
    "\n",
    "    # Compute totals for normalization\n",
    "    total_likelihood = sum(valid_likelihoods.values())\n",
    "    total_rel_ewma = sum(rel_ewma.values())\n",
    "\n",
    "    # Skip wealth redistribution if still warming up\n",
    "    if total_likelihood == 0 or total_rel_ewma == 0 or not wealth_update:\n",
    "        return\n",
    "\n",
    "    # Investment phase\n",
    "    # - For each prediction round, players automatically invest a fraction of their active wealth into the pot.\n",
    "    # - This amount is subtracted from their active wealth.\n",
    "    # - Players can skip predictions. Doing so means they cannot lose or gain wealth, as they are not participating in prize distribution.\n",
    "    pot = 0.0\n",
    "    for name, player in players.items():\n",
    "        if name in valid_likelihoods:\n",
    "            investment = params[\"investment_fraction\"] * player[\"wealth\"]\n",
    "            player[\"wealth\"] = max(0.0, player[\"wealth\"] - investment) # - Player wealth will never go below 0.\n",
    "            pot += investment\n",
    "\n",
    "    # Note: player wealth with 0:\n",
    "    # Even if your wealth reaches zero, you can still make a comeback.\n",
    "    # Since your investment will be zero, you won't lose anything more, but you can still earn from the shared pot if your tracker performs well.\n",
    "\n",
    "    # Inflation adjustment\n",
    "    # - The total pot is inflated slightly by a game-defined inflation rate.\n",
    "    pot *= 1 + params[\"inflation_bps\"] / 10000.0\n",
    "\n",
    "    # Redistribution phase\n",
    "    # - Once the true dove location is revealed, each prediction is scored using a likelihood function.\n",
    "    # - The pot is then distributed proportionally based on these likelihood scores.\n",
    "    # - More accurate predictions earn a larger share of the pot.\n",
    "    for name in valid_likelihoods:\n",
    "        instant_share = valid_likelihoods[name] / total_likelihood\n",
    "        long_term_share = rel_ewma[name] / total_rel_ewma if name in rel_ewma else 0\n",
    "        # Blend short-term and long-term performance\n",
    "        share = (1 - ewma_weight) * instant_share + ewma_weight * long_term_share\n",
    "        players[name][\"wealth\"] += pot * share\n",
    "\n",
    "\n",
    "def run_simulation_wealth(trackers, live=LIVE_MODE, max_rows=MAX_ROWS, game_params=GAME_PARAMS,\n",
    "                          warmup_steps_all_models=WARMUP_STEPS_ALL_MODELS, log_every_n_steps=LOG_EVERY_N_STEPS):\n",
    "    \"\"\"\n",
    "    Run the live or remote wealth distribution simulation with multiple trackers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trackers : list\n",
    "        List of tracker instances to evaluate.\n",
    "    live : bool\n",
    "        Whether to use live data or remote test data.\n",
    "    max_rows : int | None\n",
    "        Maximum rows to fetch from remote data generator.\n",
    "    game_params : dict\n",
    "        Dictionary with keys: 'initial_wealth', 'investment_fraction', 'inflation_bps'.\n",
    "    warmup_steps_all_models : int\n",
    "        Number of steps to warm up trackers.\n",
    "    log_every_n_steps : int\n",
    "        Logging frequency for wealth snapshots.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Updates player wealth over the simulation.\n",
    "    \"\"\"\n",
    "    gen = live_data_generator() if live else remote_test_data_generator(max_rows=max_rows)\n",
    "    evaluators = {t.__class__.__name__: TrackerEvaluator(t) for t in trackers}\n",
    "\n",
    "    # Player setup\n",
    "    players = {\n",
    "        name: {\n",
    "            \"tracker_evaluator\": evaluator,\n",
    "            \"wealth\": game_params[\"initial_wealth\"],\n",
    "        }\n",
    "        for name, evaluator in evaluators.items()\n",
    "    }\n",
    "\n",
    "    nb_update = 0  # count of updates skipped for EWMA warmup\n",
    "\n",
    "    try:\n",
    "        for i, payload in enumerate(tqdm(gen)):\n",
    "            likelihoods = {\n",
    "                name: compute_likelihood(p[\"tracker_evaluator\"], payload)\n",
    "                for name, p in players.items()\n",
    "            }\n",
    "\n",
    "            # Only start wealth updates after a warmup period\n",
    "            # (here for simplicity: we update wealth only if all models have valid likelihood)\n",
    "            if i > warmup_steps_all_models and not any(v is None for v in likelihoods.values()):\n",
    "                \n",
    "                # During first updates, skip redistribution to stabilize EWMA\n",
    "                if nb_update < 1000:\n",
    "                    wealth_update = False\n",
    "                    nb_update += 1\n",
    "                else:\n",
    "                    wealth_update = True\n",
    "\n",
    "                update_wealth(players, likelihoods, game_params, wealth_update=wealth_update)\n",
    "\n",
    "                if i % log_every_n_steps == 0:\n",
    "                    snapshot = {name: round(p[\"wealth\"], 2) for name, p in players.items()}\n",
    "                    logging.info(f\"Step {i:05d} | Wealth: {snapshot}\")\n",
    "\n",
    "                    # snapshot_ewma = {name: players[name][\"ewma_logL\"] for name in players}\n",
    "                    # logging.info(f\"Step {i:05d} | EWMA log-likelihood: {snapshot_ewma}\")\n",
    "                    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd31a2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242baa757685415ab56e867dd0ac2f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-04 14:18:39,311] Step 00600 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:18:39,311] Step 00600 | EWMA log-likelihood: {'EMWAVarTracker': -0.26955263250722766, 'QuantileRegressionRiverTracker': -3.7351259065232023, 'CustomTracker': 0.9378719284071424}\n",
      "[2025-11-04 14:18:46,429] Step 00700 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:18:46,429] Step 00700 | EWMA log-likelihood: {'EMWAVarTracker': -0.1021928977941466, 'QuantileRegressionRiverTracker': -4.191517084199391, 'CustomTracker': 0.9010885284727204}\n",
      "[2025-11-04 14:18:53,409] Step 00800 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:18:53,413] Step 00800 | EWMA log-likelihood: {'EMWAVarTracker': -0.7020239578892726, 'QuantileRegressionRiverTracker': -5.8431626004666075, 'CustomTracker': -0.9579281833607862}\n",
      "[2025-11-04 14:19:00,827] Step 00900 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:00,827] Step 00900 | EWMA log-likelihood: {'EMWAVarTracker': -1.0484608077680273, 'QuantileRegressionRiverTracker': -7.002723015256682, 'CustomTracker': -2.9293474412602203}\n",
      "[2025-11-04 14:19:08,428] Step 01000 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:08,428] Step 01000 | EWMA log-likelihood: {'EMWAVarTracker': -1.243616677995153, 'QuantileRegressionRiverTracker': -6.377068333568678, 'CustomTracker': -5.281140754523233}\n",
      "[2025-11-04 14:19:16,939] Step 01100 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:16,940] Step 01100 | EWMA log-likelihood: {'EMWAVarTracker': -1.1361932075671066, 'QuantileRegressionRiverTracker': -7.435263816004216, 'CustomTracker': -5.8004486636089725}\n",
      "[2025-11-04 14:19:24,687] Step 01200 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:24,691] Step 01200 | EWMA log-likelihood: {'EMWAVarTracker': -0.9819040804836044, 'QuantileRegressionRiverTracker': -7.797415666074398, 'CustomTracker': -6.145993007623312}\n",
      "[2025-11-04 14:19:32,442] Step 01300 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:32,442] Step 01300 | EWMA log-likelihood: {'EMWAVarTracker': -0.7826513699142855, 'QuantileRegressionRiverTracker': -8.848810071623008, 'CustomTracker': -6.039178310008347}\n",
      "[2025-11-04 14:19:39,365] Step 01400 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:39,365] Step 01400 | EWMA log-likelihood: {'EMWAVarTracker': -0.5796672144090418, 'QuantileRegressionRiverTracker': -10.024932191429023, 'CustomTracker': -5.8824616229023805}\n",
      "[2025-11-04 14:19:45,849] Step 01500 | Wealth: {'EMWAVarTracker': 1000, 'QuantileRegressionRiverTracker': 1000, 'CustomTracker': 1000}\n",
      "[2025-11-04 14:19:45,850] Step 01500 | EWMA log-likelihood: {'EMWAVarTracker': -0.37092584653330335, 'QuantileRegressionRiverTracker': -9.46256288107574, 'CustomTracker': -5.579635782229088}\n",
      "[2025-11-04 14:19:53,741] Step 01600 | Wealth: {'EMWAVarTracker': 1001.83, 'QuantileRegressionRiverTracker': 999.0, 'CustomTracker': 999.17}\n",
      "[2025-11-04 14:19:53,741] Step 01600 | EWMA log-likelihood: {'EMWAVarTracker': -0.32381908318464075, 'QuantileRegressionRiverTracker': -11.108831680780966, 'CustomTracker': -6.231987176140388}\n",
      "[2025-11-04 14:20:00,808] Step 01700 | Wealth: {'EMWAVarTracker': 1003.37, 'QuantileRegressionRiverTracker': 998.04, 'CustomTracker': 998.6}\n",
      "[2025-11-04 14:20:00,824] Step 01700 | EWMA log-likelihood: {'EMWAVarTracker': -0.11230839567414692, 'QuantileRegressionRiverTracker': -12.222913071725506, 'CustomTracker': -5.700232038646429}\n",
      "[2025-11-04 14:20:08,541] Step 01800 | Wealth: {'EMWAVarTracker': 1004.77, 'QuantileRegressionRiverTracker': 997.18, 'CustomTracker': 998.06}\n",
      "[2025-11-04 14:20:08,541] Step 01800 | EWMA log-likelihood: {'EMWAVarTracker': 0.0969798471027441, 'QuantileRegressionRiverTracker': -12.952619305876308, 'CustomTracker': -5.083962464284636}\n",
      "[2025-11-04 14:20:15,808] Step 01900 | Wealth: {'EMWAVarTracker': 1006.2, 'QuantileRegressionRiverTracker': 996.2, 'CustomTracker': 997.6}\n",
      "[2025-11-04 14:20:15,808] Step 01900 | EWMA log-likelihood: {'EMWAVarTracker': 0.26731725589527705, 'QuantileRegressionRiverTracker': -14.229742521638983, 'CustomTracker': -4.670541440628687}\n",
      "[2025-11-04 14:20:23,440] Step 02000 | Wealth: {'EMWAVarTracker': 1008.04, 'QuantileRegressionRiverTracker': 995.2, 'CustomTracker': 996.76}\n",
      "[2025-11-04 14:20:23,456] Step 02000 | EWMA log-likelihood: {'EMWAVarTracker': 0.3579642495540813, 'QuantileRegressionRiverTracker': -15.505649482532267, 'CustomTracker': -4.795928896504181}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted\n"
     ]
    }
   ],
   "source": [
    "trackers = [\n",
    "        EMWAVarTracker(),\n",
    "        QuantileRegressionRiverTracker(),\n",
    "        CustomTracker(),   # here: AutoETS quickstarter\n",
    "    ]\n",
    "\n",
    "run_simulation_wealth(trackers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
